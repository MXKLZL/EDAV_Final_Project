[
["index.html", "YOUR TITLE HERE Chapter 1 Introduction", " YOUR TITLE HERE Yichi Zhang, Zelin Li, Huayun Xu, Mingfang Chang 2019-12-11 Chapter 1 Introduction Many full-time students at Columbia, including us, are living off campus currently and may need to find new housing in next semester or next year. Among all the considerations while searching available apartments, we care most about the safety of areas surrounding the apartment. However, when googling the crime rate analysis, we found that they are not very instructive, as there are many crime types are included that irrelevent to us, like kidnapping. Hence the objective of our final project is that based on the crime types we care about, find the relatively safe areas by researching the crime rate of five boroughts, Manhattan, Bronx, Brooklyn, Queens and Staten Island, in New York City, which can be regarded as a reference of safety for people who are finding housing. "],
["data-sources.html", "Chapter 2 Data sources", " Chapter 2 Data sources We got the data of crime events to be researched from NYC Open Data, and the link is as following: https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243/data This dataset includes all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department (NYPD) for all complete quarters so far this year (2019). Because we found the data in the end of October, the data is up to September, 2019. Then we downloaded the dataset as a csv file, and we also downloaded the explanation of each column name as a pdf file found from “About” in the right side of the website. The dataset is read by following code: library(tidyr) library(tidyverse) DATA &lt;- read.csv(&quot;NYPD_Complaint_Data_Current__Year_To_Date_.csv&quot;, na.strings = &quot;&quot;) Another dataset is the population in each of 5 boroughs in New York City in 2018, and we downloaded it from the following link: https://www.census.gov/quickfacts/fact/table/newyorkcountymanhattanboroughnewyork,bronxcountybronxboroughnewyork,queenscountyqueensboroughnewyork,kingscountybrooklynboroughnewyork,richmondcountystatenislandboroughnewyork,newyorkcitynewyork/HSG010218 Because currently we are in 2019 and there is no data of population in the end of 2019, we will use this dataset to calculate the crime rate for each borough in the later research. Dataset reading is shown in later chapter. "],
["data-transformation.html", "Chapter 3 Data transformation", " Chapter 3 Data transformation library(tidyr) library(tidyverse) library(dplyr) library(lubridate) library(chron) DATA &lt;- read.csv(&quot;NYPD_Complaint_Data_Current__Year_To_Date_.csv&quot;,na.strings = &quot;&quot;) DATA &lt;-DATA[!is.na(DATA$CMPLNT_FR_DT), ] DATA$CMPLNT_FR_DT &lt;-as.Date(DATA$CMPLNT_FR_DT,format = &quot;%m/%d/%Y&quot;) for(i in 1:nrow(DATA)){ if(year(DATA[i,4]) ==&#39;1018&#39;){year(DATA[i,4]) &lt;-2018} if(year(DATA[i,4]) ==&#39;1019&#39;){year(DATA[i,4]) &lt;-2019} if(year(DATA[i,4]) ==&#39;1029&#39;){year(DATA[i,4]) &lt;-2019} } DATA$CMPLNT_FR_TM &lt;-as.character(DATA$CMPLNT_FR_TM) DATA$CMPLNT_FR_TM &lt;-chron(times=DATA$CMPLNT_FR_TM) df &lt;- DATA %&gt;% filter(CMPLNT_FR_DT &gt;=as.Date(&#39;2018-01-01&#39;)) offense &lt;- c(&#39;ANTICIPATORY OFFENSES&#39;, &quot;OFF. AGNST PUB ORD SENSBLTY &amp;&quot;, &quot;OFFENSES AGAINST MARRIAGE UNCL&quot;, &quot;OFFENSES AGAINST PUBLIC ADMINI&quot;, &quot;OFFENSES AGAINST PUBLIC SAFETY&quot;, &quot;OFFENSES AGAINST THE PERSON&quot;, &quot;OFFENSES INVOLVING FRAUD&quot;, &quot;OFFENSES RELATED TO CHILDREN&quot;, &quot;OTHER OFFENSES RELATED TO THEF&quot;) assault &lt;- c(&#39;ASSAULT 3 &amp; RELATED OFFENSES&#39;, &#39;FELONY ASSAULT&#39;, &quot;HARRASSMENT 2&quot;) burglary &lt;- c(&#39;BURGLARY&#39;, &quot;BURGLAR&#39;S TOOLS&quot;, &quot;CRIMINAL TRESPASS&quot;) drug &lt;- c(&quot;DANGEROUS DRUGS&quot;) weapon &lt;- c(&quot;DANGEROUS WEAPONS&quot;, &quot;UNLAWFUL POSS. WEAP. ON SCHOOL&quot; ) rape &lt;- c(&quot;FELONY SEX CRIMES&quot;, &quot;RAPE&quot;, &quot;SEX CRIMES&quot;) fraud &lt;- c(&quot;FRAUDS&quot;, &quot;FORGERY&quot;, &quot;FRAUDULENT ACCOSTING&quot;, &quot;THEFT-FRAUD&quot;) thief &lt;- c(&quot;GRAND LARCENY&quot;, &quot;GRAND LARCENY OF MOTOR VEHICLE&quot;, &quot;OTHER OFFENSES RELATED TO THEF&quot;, &quot;PETIT LARCENY&quot;, &quot;PETIT LARCENY OF MOTOR VEHICLE&quot;, &quot;POSSESSION OF STOLEN PROPERTY&quot;, &quot;THEFT OF SERVICES&quot;) murder &lt;- c(&quot;MURDER &amp; NON-NEGL. MANSLAUGHTER&quot;) kidnapping &lt;- c(&quot;KIDNAPPING&quot;, &quot;KIDNAPPING &amp; RELATED OFFENSES&quot;, &quot;KIDNAPPING AND RELATED OFFENSES&quot;) picked &lt;- c(&#39;ROBBERY&#39;, &quot;OFFENSE&quot;, &quot;ARSON&quot;, &quot;BURGLARY&quot;, &quot;DRUG&quot;, &quot;WEAPON&quot;, &quot;RAPE&quot;, &quot;FRAUD&quot;, &quot;THIEF&quot;, &quot;MURDER&quot;, &quot;KIDNAPPING&quot;) df$OFNS_DESC &lt;- as.character(df$OFNS_DESC) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% offense, &quot;OFFENSE&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% assault, &quot;ASSAULT&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% drug, &quot;DRUG&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% weapon, &quot;WEAPON&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% rape, &quot;RAPE&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% fraud, &quot;FRAUD&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% thief, &quot;THIEF&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% murder, &quot;MURDER&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% kidnapping, &quot;KIDNAPPING&quot;, OFNS_DESC)) df &lt;- df %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% picked, OFNS_DESC, NA)) %&gt;% drop_na(OFNS_DESC) cols &lt;- c(&#39;BORO_NM&#39;, &#39;CMPLNT_FR_DT&#39;,&#39;CMPLNT_FR_TM&#39;,&#39;OFNS_DESC&#39;, &#39;SUSP_AGE_GROUP&#39;, &#39;PREM_TYP_DESC&#39;, &#39;SUSP_SEX&#39;, &#39;SUSP_RACE&#39;, &#39;VIC_AGE_GROUP&#39;, &#39;VIC_RACE&#39;, &#39;VIC_SEX&#39;, &#39;Latitude&#39;, &#39;Longitude&#39;) df_select &lt;- df[, cols] "],
["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values df_cols &lt;- colnames(df_select) df &lt;- df_select %&gt;% mutate(CMPLNT_FR_DT=as.Date(CMPLNT_FR_DT, &quot;%m/%d/%Y&quot;)) %&gt;% filter(CMPLNT_FR_DT &gt;= as.Date(&quot;01/01/2018&quot;, &quot;%m/%d/%Y&quot;)) %&gt;% sample_n(1000) #df &lt;- df %&gt;% select(-timerange, -color, -crimecolor) df &lt;- df %&gt;% mutate(SUSP_AGE_GROUP = ifelse(SUSP_AGE_GROUP == &quot;UNKNOWN&quot;, NA, SUSP_AGE_GROUP)) df &lt;- df %&gt;% mutate(SUSP_RACE = ifelse(SUSP_RACE == &quot;UNKNOWN&quot;, NA, SUSP_RACE)) df &lt;- df %&gt;% mutate(VIC_AGE_GROUP = ifelse(VIC_AGE_GROUP == &quot;UNKNOWN&quot;, NA, VIC_AGE_GROUP)) df &lt;- df %&gt;% mutate(VIC_RACE = ifelse(VIC_RACE == &quot;UNKNOWN&quot;, NA, VIC_RACE)) We have randomly sampled 1000 data to analysis the missing value pattern of the dataset after we have cleaned the data. We have also changed the “UNKNOWN” entry to NA. vis_miss(df) From the plot above, we see that majority of missing data came from the columns: “SUSP_AGE_GEOUP”, “SUSP_SEX”, “SUSP_RACE”, “VIC_AGE_GROUP”, “VIC_RACE”, “Latitude”, and “Longitude”. We also see that “Latitude”, and “Longitude” are always missing together. df$CMPLNT_FR_DT &lt;- as.character(df$CMPLNT_FR_DT) df$CMPLNT_FR_TM &lt;- as.character(df$CMPLNT_FR_TM) names(df) &lt;- df_cols x &lt;- missing_data.frame(df) ## NOTE: In the following pairs of variables, the missingness pattern of the second is a subset of the first. ## Please verify whether they are in fact logically distinct variables. ## [,1] [,2] ## [1,] &quot;SUSP_AGE_GROUP&quot; &quot;SUSP_SEX&quot; summary(x@patterns) ## nothing ## 7 ## SUSP_AGE_GROUP ## 2 ## VIC_RACE ## 1 ## SUSP_AGE_GROUP, SUSP_RACE ## 12 ## VIC_AGE_GROUP, VIC_RACE ## 13 ## Latitude, Longitude ## 145 ## SUSP_AGE_GROUP, Latitude, Longitude ## 65 ## SUSP_AGE_GROUP, VIC_AGE_GROUP, VIC_RACE ## 2 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE ## 13 ## VIC_AGE_GROUP, Latitude, Longitude ## 1 ## VIC_RACE, Latitude, Longitude ## 5 ## SUSP_RACE, Latitude, Longitude ## 3 ## SUSP_RACE, VIC_AGE_GROUP, VIC_RACE ## 1 ## VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 202 ## SUSP_AGE_GROUP, SUSP_RACE, Latitude, Longitude ## 149 ## SUSP_RACE, VIC_RACE, Latitude, Longitude ## 2 ## SUSP_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 3 ## BORO_NM, PREM_TYP_DESC, Latitude, Longitude ## 1 ## SUSP_AGE_GROUP, PREM_TYP_DESC, Latitude, Longitude ## 1 ## SUSP_AGE_GROUP, VIC_AGE_GROUP, Latitude, Longitude ## 2 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE, Latitude, Longitude ## 192 ## SUSP_AGE_GROUP, VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 37 ## SUSP_AGE_GROUP, SUSP_RACE, VIC_RACE, Latitude, Longitude ## 5 ## SUSP_RACE, VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 2 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE, VIC_AGE_GROUP, VIC_RACE ## 1 ## SUSP_AGE_GROUP, SUSP_RACE, VIC_AGE_GROUP, Latitude, Longitude ## 1 ## SUSP_AGE_GROUP, SUSP_RACE, VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 37 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE, VIC_AGE_GROUP, Latitude, Longitude ## 5 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE, VIC_RACE, Latitude, Longitude ## 8 ## SUSP_AGE_GROUP, PREM_TYP_DESC, SUSP_SEX, SUSP_RACE, VIC_AGE_GROUP, VIC_RACE ## 1 ## SUSP_AGE_GROUP, PREM_TYP_DESC, VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 1 ## SUSP_AGE_GROUP, SUSP_SEX, SUSP_RACE, VIC_AGE_GROUP, VIC_RACE, Latitude, Longitude ## 80 #image(x) We can further investigate the missing row patterns by using the missing_data.frame function, and we found out that there are 30 different row missing patterns. Some of the patterns only have one or two ocurrences and 20 of them have 10 ocurrences or below. We can check how many time each of the row missing pattern appears in the data set by the following and also visualize these row missing patterns with visna function. visna(df, sort=&#39;r&#39;) ## Warning in melt(as.data.frame(xs), ncol(xs)): The melt generic in ## data.table has been passed a data.frame and will attempt to redirect to the ## relevant reshape2 method; please note that reshape2 is deprecated, and this ## redirection is now deprecated as well. To continue using melt methods from ## reshape2 while both libraries are attached, e.g. melt.list, you can prepend ## the namespace like reshape2::melt(as.data.frame(xs)). In the next version, ## this warning will become an error. By using the visna function, we observed the following missing row patterns: The pattern that occurs the most is missing both Latitude and Longitude, which is about 91.5% of the data. The information of the suspect are missing such as age, sex, and race tends to be missing along with some other variables. Since the objective of our project is to analysis the safty issue, when doing the interative part of the project, we will need to use the location information. So we have to drop all the data with Longitude and Latitude missing. This might affect the distribution of the crime, so we plotted the following diagram to compare the distribution of crime type before and after when location is removed. ggplot(df_select, aes(x=OFNS_DESC, y=..count..)) + geom_bar() + labs(title=&quot;Count by crime type&quot;) df_locationNA_dropped &lt;- df_select %&gt;% drop_na(Latitude) ggplot(df_locationNA_dropped, aes(x=OFNS_DESC, y=..count..)) + geom_bar() + labs(title=&quot;Count by crime type with location NA dropped&quot;) Base on the above two plots, we see that after we have removed all the data that are missing location, the distribution of the crime type is unchanged. So, the missing of location is somewhat random and we are safe to remove it when doing the interactive part. "],
["results.html", "Chapter 5 Results", " Chapter 5 Results library(dplyr) library(choroplethrMaps) library(choroplethr) library(ggplot2) library(viridis) library(chron) library(tidyverse) df1 &lt;- data.frame(df_select[,4]) df1[&#39;count&#39;] &lt;- 1 df1&lt;- df1 %&gt;% group_by(df_select...4.) %&gt;% summarize(Freq = sum(count)) ggplot(df1, aes(reorder(df_select...4.,df1$Freq), y = df1$Freq)) + geom_bar(position = &quot;dodge&quot;,stat = &quot;identity&quot;,fill=&quot;lightblue&quot;) + scale_y_continuous(trans=&#39;log2&#39;)+ coord_flip() + labs(x = &quot;Crime Types&quot;, y = &quot;Total amount&quot;, title = &quot;Major Crimes in NYC&quot;) dangerous &lt;-c(&#39;BURGLARY&#39;,&#39;OFFENSE&#39;,&#39;RAPE&#39;,&#39;ROBBERY&#39;,&#39;THIEF&#39;,&#39;WEAPON&#39;) df_select &lt;- df_select %&gt;% mutate(OFNS_DESC = ifelse(OFNS_DESC %in% dangerous, OFNS_DESC, NA)) %&gt;% drop_na(OFNS_DESC) df_select &lt;- drop_na(df_select, BORO_NM) DATA2 &lt;- read.csv(&quot;QuickFacts.csv&quot;) DATA2 &lt;-DATA2[, colSums(is.na(DATA2)) != nrow(DATA2)] DATA2 &lt;-DATA2[,-c(2,8)] DATA2 &lt;-as.data.frame(t(DATA2)) names(DATA2) &lt;- as.character(unlist(DATA2[1,])) DATA2 &lt;- DATA2[-1,] DATA2 &lt;-as.data.frame(DATA2[,1]) names(DATA2)&lt;-&#39;Population&#39; row.names(DATA2) &lt;-c(&#39;MANHATTAN&#39;,&#39;BRONX&#39;,&#39;QUEENS&#39;,&#39;BROOKLYN&#39;,&#39;STATEN ISLAND&#39;) ChorDF &lt;-df_select%&gt;% group_by(df_select$BORO_NM) %&gt;% summarise(count=n())%&gt;% ungroup() ChorDF &lt;- data.frame(ChorDF[,-1], row.names = unlist(ChorDF[,1])) ChorDF &lt;- merge(ChorDF,DATA2,by = 0) ChorDF$count &lt;-as.numeric(ChorDF$count) ChorDF$Population &lt;-as.numeric((gsub(&quot;\\\\,&quot;, &quot;&quot;, ChorDF$Population))) ChorDF &lt;-ChorDF %&gt;% mutate(rate = as.double(count/Population)*100000) ChorDF[,&#39;region&#39;] &lt;- NA for(i in 1:nrow(ChorDF)){ if(ChorDF[i,1] == &#39;BRONX&#39;){ChorDF[i,&#39;region&#39;] &lt;-36005} if(ChorDF[i,1] == &#39;BROOKLYN&#39;){ChorDF[i,&#39;region&#39;] &lt;-36047} if(ChorDF[i,1] == &#39;MANHATTAN&#39;){ChorDF[i,&#39;region&#39;] &lt;-36061} if(ChorDF[i,1] == &#39;QUEENS&#39;){ChorDF[i,&#39;region&#39;] &lt;- 36081} if(ChorDF[i,1] == &#39;STATEN ISLAND&#39;){ChorDF[i,&#39;region&#39;] &lt;-36085} } colnames(ChorDF)[4] &lt;-&#39;value&#39; data(county.regions) nyc_county_names = c(&quot;kings&quot;, &quot;bronx&quot;, &quot;new york&quot;, &quot;queens&quot;, &quot;richmond&quot;) nyc_county_fips = county.regions %&gt;% filter(state.name == &quot;new york&quot; &amp; county.name %in% nyc_county_names) %&gt;% select(region) county_choropleth(ChorDF, title = &quot;Number of Selected Crime per 100000 Population for Five Borough&quot;, legend = &quot;Crime Rate&quot;, county_zoom = nyc_county_fips$region) ## Warning in min(xx[xx &gt; upper]): no non-missing arguments to min; returning ## Inf As full-time students, we go out more frequently from Monday to Friday rather than weekends. Therefore we want to know the days with the most and least frequent number of crime events for each borough, and the plot is as following: library(chron) library(ggplot2) ggplot(df_select, aes(factor(weekdays(CMPLNT_FR_DT,abbreviate =TRUE), levels=c(&quot;Mon&quot;, &quot;Tue&quot;, &quot;Wed&quot;, &quot;Thu&quot;, &quot;Fri&quot;, &quot;Sat&quot;, &quot;Sun&quot;))))+ geom_bar(fill=&quot;lightblue&quot;)+ xlab(&quot;Weekdays&quot;)+ ggtitle(&quot;The Number of Crime Events in Weekdays by Borough in New York City&quot;)+ facet_wrap(&quot;BORO_NM&quot;, scale=&quot;free&quot;) Based on the above plot, the weekdays pattern is similar for each borough, where in the weekends the occurance of crime events is relatively infrequently compare to weekdays. Moreover, it seems that Staten Island is the best place to live if only safety is considered. df2 &lt;- data.frame(df_select[,1:2]) df2[&#39;count&#39;] &lt;- 1 df2&lt;- df2 %&gt;% group_by(CMPLNT_FR_DT) %&gt;% summarize(Freq = sum(count)) df2 &lt;- df2 %&gt;% filter(CMPLNT_FR_DT &gt;=as.Date(&#39;2019-01-01&#39;)) ggplot(df2, aes(as.Date(CMPLNT_FR_DT), y = Freq)) + geom_line(color=&quot;orange&quot;)+ ylim(0, 900) + labs(x = &quot;Time&quot;, y = &quot;Total amount&quot;, title = &quot;Time series pattern in 2019&quot;) df2 &lt;- data.frame(df_select[,1:2]) df2[&#39;count&#39;] &lt;- 1 df2 &lt;-df2[!is.na(df2$BORO_NM), ] df2&lt;- df2 %&gt;% group_by(BORO_NM,CMPLNT_FR_DT) %&gt;% summarize(Freq = sum(count)) df2 &lt;- df2 %&gt;% filter(CMPLNT_FR_DT &gt;=as.Date(&#39;2019-01-01&#39;)) df2[&quot;adjusted&quot;] &lt;- 0 df3 &lt;- data.frame(df2) DA &lt;- data.frame(DATA2) DA$Population &lt;-as.numeric((gsub(&quot;\\\\,&quot;, &quot;&quot;, DA$Population))) for(i in 1:1365){ states &lt;- df3[i,1] df3[i,&#39;adjusted&#39;]&lt;-100000*df3[i,3]/DA[states,&quot;Population&quot;] } ggplot(df3, aes(as.Date(CMPLNT_FR_DT), y = Freq)) + geom_line(color=&quot;orange&quot;) + facet_wrap(~BORO_NM, scales=&quot;free_y&quot;,ncol = 2)+ labs(x = &quot;Time&quot;, y = &quot;Crime Rate&quot;, title = &quot;Time series pattern in 2019 in different boroughs&quot;) #Cleveland dot plot library(tidyverse) cleveland &lt;-df_select[,c(&#39;BORO_NM&#39;,&#39;OFNS_DESC&#39;)] cleveland[&#39;Freq&#39;] = 1 cleveland &lt;- cleveland %&gt;% group_by(BORO_NM,OFNS_DESC) %&gt;% summarize(Freq = log(sum(Freq),2)) %&gt;% ungroup() theme_dotplot &lt;- theme_bw(14) + theme(axis.text.y = element_text(size = rel(.55)), axis.text.x = element_text(size = rel(.70)), axis.ticks.y = element_blank(), axis.title.x = element_text(size = rel(.70)), axis.title.y = element_text(size = rel(.70)), panel.grid.major.x = element_blank(), panel.grid.major.y = element_line(size = 0.5), panel.grid.minor.x = element_blank()) ggplot(cleveland,aes(Freq,fct_reorder2(BORO_NM, OFNS_DESC == &#39;THIEF&#39;,Freq, .desc = FALSE),color = OFNS_DESC))+ geom_point()+ ylab(&#39;Boroughs&#39;)+ xlab(&#39;Crime Rate&#39;)+ labs(title = &#39;Crime rate for each type by Boroughs &#39;,color = &quot;Crime Type&quot;)+ theme_dotplot picked_time &lt;- c(&quot;07am - 11am&quot;, &quot;15pm - 19pm&quot;, &quot;19pm - 23pm&quot;) crime_color &lt;- c(&quot;#7851a9&quot;, &quot;#800020&quot;, &quot;#ef5927&quot;, &quot;#0079c1&quot;, &quot;#dac751&quot;, &quot;#133a30&quot;) df_select &lt;- df_select %&gt;% drop_na(BORO_NM) df_select &lt;- df_select %&gt;% mutate(timerange = CMPLNT_FR_TM) df_select &lt;- df_select %&gt;% mutate(timerange = ifelse(CMPLNT_FR_TM &gt;= chron(times=&quot;07:00:00&quot;) &amp; CMPLNT_FR_TM &lt;= chron(times=&quot;11:00:00&quot;), &quot;07am - 11am&quot;, timerange) ) df_select &lt;- df_select %&gt;% mutate(timerange = ifelse(CMPLNT_FR_TM &gt;= chron(times=&quot;15:00:00&quot;) &amp; CMPLNT_FR_TM &lt;= chron(times=&quot;19:00:00&quot;), &quot;15pm - 19pm&quot;, timerange) ) df_select &lt;- df_select %&gt;% mutate(timerange = ifelse(CMPLNT_FR_TM &gt;= chron(times=&quot;19:00:00&quot;) &amp; CMPLNT_FR_TM &lt;= chron(times=&quot;23:00:00&quot;), &quot;19pm - 23pm&quot;, timerange) ) df_select &lt;- df_select %&gt;% mutate(color = timerange) df_select &lt;- df_select %&gt;% mutate( color = ifelse(timerange == picked_time[1], &quot;red&quot;, color) ) df_select &lt;- df_select %&gt;% mutate( color = ifelse(timerange == picked_time[2], &quot;green&quot;, color) ) df_select &lt;- df_select %&gt;% mutate( color = ifelse(timerange == picked_time[3], &quot;blue&quot;, color) ) df_select &lt;- df_select %&gt;% mutate(crimecolor = OFNS_DESC) for(i in 1:length(dangerous)){ df_select &lt;- df_select %&gt;% mutate( crimecolor = ifelse(OFNS_DESC == dangerous[i], crime_color[i], crimecolor) ) } df_select &lt;- df_select %&gt;% mutate(timerange = ifelse(timerange %in% picked_time, timerange, NA)) %&gt;% drop_na(timerange) ggplot(df_select, aes(x=OFNS_DESC, ..count.., fill=timerange)) + geom_bar(position=&quot;dodge&quot;) + facet_wrap(~BORO_NM, ncol=2,scales=&quot;free_x&quot;) + scale_y_continuous(trans=&#39;log2&#39;) Because we are all in the age group 18-24, and we want to find how we are related to the victims of crime events, first we plot the distribution of 5 age groups from &lt;18 to 65+ in each borough, and the result is as following: df_age &lt;- subset(df_select, as.character(VIC_AGE_GROUP) %in% c(&quot;&lt;18&quot;, &quot;18-24&quot;, &quot;25-44&quot;, &quot;45-64&quot;,&quot;65+&quot;) ) ggplot(df_age, aes(VIC_AGE_GROUP))+ geom_bar(fill=&quot;lightblue&quot;)+ xlab(&quot;Age Groups&quot;)+ ggtitle(&quot;The Distribution of Age Groups of Victims by Borough in New York City&quot;)+ facet_wrap(&quot;BORO_NM&quot;, scale=&quot;free&quot;) According to the graphs, we found that for each borough, the pattern of victims age group is similar, where the 25-44 age group has the largest number of victims, and the 45-64 age group has the second largest number of victims. For this plot it seems that the 18-24 age group among different boroughs is not apparent, so we extract the 18-24 group of each borough and draw the following barplot: df_age2&lt;-subset(df_age, as.character(VIC_AGE_GROUP)==&quot;18-24&quot;) #df_age2 &lt;- df_age2$VIC_AGE_GROUP df_age2 &lt;-df_age2%&gt;% group_by(df_age2$BORO_NM) %&gt;% summarise(count=n())%&gt;% ungroup() names(df_age2)[1] &lt;- &quot;Borough&quot; df_age2$count &lt;- df_age2$count/ChorDF$Population*100000 names(df_age2)[2] &lt;- &quot;Rate&quot; ggplot(df_age2, aes(x=reorder(Borough, -Rate), y=Rate))+ geom_bar(stat = &quot;identity&quot;,fill=&quot;lightblue&quot;)+ xlab(&quot;Boroughs&quot;)+ ggtitle(&quot;The Number of Victims per 100000 People in 18-24 Age Group by Borough in New York City&quot;) For this plot, we convert the count of crime events to crime rate per 100000 people, and we can see clearly that Manhattan has the largest crime rate, while staten island has the smallest crime rate. df_race &lt;-df_select[,c(&#39;OFNS_DESC&#39;,&#39;VIC_RACE&#39;)] df_race &lt;- df_race %&gt;% filter(VIC_RACE != &#39;UNKNOWN&#39;) df_race[&#39;count&#39;] &lt;- 1 df_race&lt;- df_race %&gt;% group_by(VIC_RACE,OFNS_DESC) %&gt;% summarize(Freq = log(sum(count))) ggplot(df_race, aes(x = OFNS_DESC, y = Freq))+ geom_bar(position = &quot;dodge&quot;,stat = &quot;identity&quot;,fill=&quot;lightblue&quot;) + facet_wrap(~VIC_RACE, scales=&quot;free&quot;, nrow = 3)+ theme(axis.text.x=element_text(size=6))+ labs(x = &quot;Crime Types&quot;, y = &quot;log(Total amount)&quot;, title = &quot;Major Crimes faced by different races in NYC&quot;) df_race &lt;-df_select[,c(&#39;BORO_NM&#39;,&#39;VIC_RACE&#39;)] df_race &lt;- df_race %&gt;% filter(VIC_RACE != &#39;UNKNOWN&#39;) df_race[&#39;count&#39;] &lt;- 1 df_race&lt;- df_race %&gt;% group_by(VIC_RACE,BORO_NM) %&gt;% summarize(Freq = sum(count)) df_race[&#39;adjusted&#39;] &lt;- 1 df_race &lt;- data.frame(df_race) for(i in 1:30){ state &lt;- df_race[i,2] df_race[i,&#39;adjusted&#39;]&lt;-100000*df3[i,3]/DA[state,&quot;Population&quot;] } ggplot(df_race, aes(x = BORO_NM, y = adjusted))+ geom_bar(position = &quot;dodge&quot;,stat = &quot;identity&quot;,fill=&quot;lightblue&quot;) + facet_wrap(~VIC_RACE, scales=&quot;free&quot;, nrow = 3)+ theme(axis.text.x=element_text(size=6))+ labs(x = &quot;Crime Types&quot;, y = &quot;Crime Rate&quot;, title = &quot;Crimes faced by different races in different Boroughs&quot;) "],
["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component "],
["conclusion.html", "Chapter 7 Conclusion", " Chapter 7 Conclusion "],
["leaflet.html", "Chapter 8 Interactive Geographic Data 8.1 Overview 8.2 Brief Description about Dataset", " Chapter 8 Interactive Geographic Data This chapter originated as a community contribution created by AkhilPunia This page is a work in progress. We appreciate any input you may have. If you would like to help improve this page, consider contributing to our repo. 8.1 Overview You would have already seen different libraries that can help one in beautifully displaying geographic data like ggmap and choroplethr. Even though these libraries provide lots of interesting features to better express information through 2-dimensional graphs, they still lack one feature: interactivity. Here comes leaflet—a library written in javascript to handle interactive maps. Fun Fact: It’s actively used by a lot of leading newspapers like The New York Times and The Washington Post. Let’s dive in. 8.2 Brief Description about Dataset For our analysis, we are using NYC Open Data about schools in New York City in 2016. You can find more about it on the Kaggle page. We will be focusing on the the distribution of different variables as a factor of geographical positions. library(tidyverse) library(leaflet) library(htmltools) library(leaflet.extras) library(viridis) #schools &lt;- read_csv(&#39;2016_school_explorer.csv&#39;) quakes ## lat long depth mag stations ## 1 -20.42 181.62 562 4.8 41 ## 2 -20.62 181.03 650 4.2 15 ## 3 -26.00 184.10 42 5.4 43 ## 4 -17.97 181.66 626 4.1 19 ## 5 -20.42 181.96 649 4.0 11 ## 6 -19.68 184.31 195 4.0 12 ## 7 -11.70 166.10 82 4.8 43 ## 8 -28.11 181.93 194 4.4 15 ## 9 -28.74 181.74 211 4.7 35 ## 10 -17.47 179.59 622 4.3 19 ## 11 -21.44 180.69 583 4.4 13 ## 12 -12.26 167.00 249 4.6 16 ## 13 -18.54 182.11 554 4.4 19 ## 14 -21.00 181.66 600 4.4 10 ## 15 -20.70 169.92 139 6.1 94 ## 16 -15.94 184.95 306 4.3 11 ## 17 -13.64 165.96 50 6.0 83 ## 18 -17.83 181.50 590 4.5 21 ## 19 -23.50 179.78 570 4.4 13 ## 20 -22.63 180.31 598 4.4 18 ## 21 -20.84 181.16 576 4.5 17 ## 22 -10.98 166.32 211 4.2 12 ## 23 -23.30 180.16 512 4.4 18 ## 24 -30.20 182.00 125 4.7 22 ## 25 -19.66 180.28 431 5.4 57 ## 26 -17.94 181.49 537 4.0 15 ## 27 -14.72 167.51 155 4.6 18 ## 28 -16.46 180.79 498 5.2 79 ## 29 -20.97 181.47 582 4.5 25 ## 30 -19.84 182.37 328 4.4 17 ## 31 -22.58 179.24 553 4.6 21 ## 32 -16.32 166.74 50 4.7 30 ## 33 -15.55 185.05 292 4.8 42 ## 34 -23.55 180.80 349 4.0 10 ## 35 -16.30 186.00 48 4.5 10 ## 36 -25.82 179.33 600 4.3 13 ## 37 -18.73 169.23 206 4.5 17 ## 38 -17.64 181.28 574 4.6 17 ## 39 -17.66 181.40 585 4.1 17 ## 40 -18.82 169.33 230 4.4 11 ## 41 -37.37 176.78 263 4.7 34 ## 42 -15.31 186.10 96 4.6 32 ## 43 -24.97 179.82 511 4.4 23 ## 44 -15.49 186.04 94 4.3 26 ## 45 -19.23 169.41 246 4.6 27 ## 46 -30.10 182.30 56 4.9 34 ## 47 -26.40 181.70 329 4.5 24 ## 48 -11.77 166.32 70 4.4 18 ## 49 -24.12 180.08 493 4.3 21 ## 50 -18.97 185.25 129 5.1 73 ## 51 -18.75 182.35 554 4.2 13 ## 52 -19.26 184.42 223 4.0 15 ## 53 -22.75 173.20 46 4.6 26 ## 54 -21.37 180.67 593 4.3 13 ## 55 -20.10 182.16 489 4.2 16 ## 56 -19.85 182.13 562 4.4 31 ## 57 -22.70 181.00 445 4.5 17 ## 58 -22.06 180.60 584 4.0 11 ## 59 -17.80 181.35 535 4.4 23 ## 60 -24.20 179.20 530 4.3 12 ## 61 -20.69 181.55 582 4.7 35 ## 62 -21.16 182.40 260 4.1 12 ## 63 -13.82 172.38 613 5.0 61 ## 64 -11.49 166.22 84 4.6 32 ## 65 -20.68 181.41 593 4.9 40 ## 66 -17.10 184.93 286 4.7 25 ## 67 -20.14 181.60 587 4.1 13 ## 68 -21.96 179.62 627 5.0 45 ## 69 -20.42 181.86 530 4.5 27 ## 70 -15.46 187.81 40 5.5 91 ## 71 -15.31 185.80 152 4.0 11 ## 72 -19.86 184.35 201 4.5 30 ## 73 -11.55 166.20 96 4.3 14 ## 74 -23.74 179.99 506 5.2 75 ## 75 -17.70 181.23 546 4.4 35 ## 76 -23.54 180.04 564 4.3 15 ## 77 -19.21 184.70 197 4.1 11 ## 78 -12.11 167.06 265 4.5 23 ## 79 -21.81 181.71 323 4.2 15 ## 80 -28.98 181.11 304 5.3 60 ## 81 -34.02 180.21 75 5.2 65 ## 82 -23.84 180.99 367 4.5 27 ## 83 -19.57 182.38 579 4.6 38 ## 84 -20.12 183.40 284 4.3 15 ## 85 -17.70 181.70 450 4.0 11 ## 86 -19.66 184.31 170 4.3 15 ## 87 -21.50 170.50 117 4.7 32 ## 88 -23.64 179.96 538 4.5 26 ## 89 -15.43 186.30 123 4.2 16 ## 90 -15.41 186.44 69 4.3 42 ## 91 -15.48 167.53 128 5.1 61 ## 92 -13.36 167.06 236 4.7 22 ## 93 -20.64 182.02 497 5.2 64 ## 94 -19.72 169.71 271 4.2 14 ## 95 -15.44 185.26 224 4.2 21 ## 96 -19.73 182.40 375 4.0 18 ## 97 -27.24 181.11 365 4.5 21 ## 98 -18.16 183.41 306 5.2 54 ## 99 -13.66 166.54 50 5.1 45 ## 100 -24.57 179.92 484 4.7 33 ## 101 -16.98 185.61 108 4.1 12 ## 102 -26.20 178.41 583 4.6 25 ## 103 -21.88 180.39 608 4.7 30 ## 104 -33.00 181.60 72 4.7 22 ## 105 -21.33 180.69 636 4.6 29 ## 106 -19.44 183.50 293 4.2 15 ## 107 -34.89 180.60 42 4.4 25 ## 108 -20.24 169.49 100 4.6 22 ## 109 -22.55 185.90 42 5.7 76 ## 110 -36.95 177.81 146 5.0 35 ## 111 -15.75 185.23 280 4.5 28 ## 112 -16.85 182.31 388 4.2 14 ## 113 -19.06 182.45 477 4.0 16 ## 114 -26.11 178.30 617 4.8 39 ## 115 -26.20 178.35 606 4.4 21 ## 116 -26.13 178.31 609 4.2 25 ## 117 -13.66 172.23 46 5.3 67 ## 118 -13.47 172.29 64 4.7 14 ## 119 -14.60 167.40 178 4.8 52 ## 120 -18.96 169.48 248 4.2 13 ## 121 -14.65 166.97 82 4.8 28 ## 122 -19.90 178.90 81 4.3 11 ## 123 -22.05 180.40 606 4.7 27 ## 124 -19.22 182.43 571 4.5 23 ## 125 -31.24 180.60 328 4.4 18 ## 126 -17.93 167.89 49 5.1 43 ## 127 -19.30 183.84 517 4.2 21 ## 128 -26.53 178.57 600 5.0 69 ## 129 -27.72 181.70 94 4.8 59 ## 130 -19.19 183.51 307 4.3 19 ## 131 -17.43 185.43 189 4.5 22 ## 132 -17.05 181.22 527 4.2 24 ## 133 -19.52 168.98 63 4.5 21 ## 134 -23.71 180.30 510 4.6 30 ## 135 -21.30 180.82 624 4.3 14 ## 136 -16.24 168.02 53 4.7 12 ## 137 -16.14 187.32 42 5.1 68 ## 138 -23.95 182.80 199 4.6 14 ## 139 -25.20 182.60 149 4.9 31 ## 140 -18.84 184.16 210 4.2 17 ## 141 -12.66 169.46 658 4.6 43 ## 142 -20.65 181.40 582 4.0 14 ## 143 -13.23 167.10 220 5.0 46 ## 144 -29.91 181.43 205 4.4 34 ## 145 -14.31 173.50 614 4.2 23 ## 146 -20.10 184.40 186 4.2 10 ## 147 -17.80 185.17 97 4.4 22 ## 148 -21.27 173.49 48 4.9 42 ## 149 -23.58 180.17 462 5.3 63 ## 150 -17.90 181.50 573 4.0 19 ## 151 -23.34 184.50 56 5.7 106 ## 152 -15.56 167.62 127 6.4 122 ## 153 -23.83 182.56 229 4.3 24 ## 154 -11.80 165.80 112 4.2 20 ## 155 -15.54 167.68 140 4.7 16 ## 156 -20.65 181.32 597 4.7 39 ## 157 -11.75 166.07 69 4.2 14 ## 158 -24.81 180.00 452 4.3 19 ## 159 -20.90 169.84 93 4.9 31 ## 160 -11.34 166.24 103 4.6 30 ## 161 -17.98 180.50 626 4.1 19 ## 162 -24.34 179.52 504 4.8 34 ## 163 -13.86 167.16 202 4.6 30 ## 164 -35.56 180.20 42 4.6 32 ## 165 -35.48 179.90 59 4.8 35 ## 166 -34.20 179.43 40 5.0 37 ## 167 -26.00 182.12 205 5.6 98 ## 168 -19.89 183.84 244 5.3 73 ## 169 -23.43 180.00 553 4.7 41 ## 170 -18.89 169.42 239 4.5 27 ## 171 -17.82 181.83 640 4.3 24 ## 172 -25.68 180.34 434 4.6 41 ## 173 -20.20 180.90 627 4.1 11 ## 174 -15.20 184.68 99 4.1 14 ## 175 -15.03 182.29 399 4.1 10 ## 176 -32.22 180.20 216 5.7 90 ## 177 -22.64 180.64 544 5.0 50 ## 178 -17.42 185.16 206 4.5 22 ## 179 -17.84 181.48 542 4.1 20 ## 180 -15.02 184.24 339 4.6 27 ## 181 -18.04 181.75 640 4.5 47 ## 182 -24.60 183.50 67 4.3 25 ## 183 -19.88 184.30 161 4.4 17 ## 184 -20.30 183.00 375 4.2 15 ## 185 -20.45 181.85 534 4.1 14 ## 186 -17.67 187.09 45 4.9 62 ## 187 -22.30 181.90 309 4.3 11 ## 188 -19.85 181.85 576 4.9 54 ## 189 -24.27 179.88 523 4.6 24 ## 190 -15.85 185.13 290 4.6 29 ## 191 -20.02 184.09 234 5.3 71 ## 192 -18.56 169.31 223 4.7 35 ## 193 -17.87 182.00 569 4.6 12 ## 194 -24.08 179.50 605 4.1 21 ## 195 -32.20 179.61 422 4.6 41 ## 196 -20.36 181.19 637 4.2 23 ## 197 -23.85 182.53 204 4.6 27 ## 198 -24.00 182.75 175 4.5 14 ## 199 -20.41 181.74 538 4.3 31 ## 200 -17.72 180.30 595 5.2 74 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 800 rows ] df &lt;- df_select %&gt;% drop_na(Latitude, Longitude) df.df &lt;- split(df, df$timerange) l &lt;- leaflet() %&gt;% addTiles() names(df.df) %&gt;% purrr::walk( function(df) { print(df) l &lt;&lt;- l %&gt;% addMarkers(data=df.df[[df]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, popup=~OFNS_DESC, group = df, clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = F), labelOptions = labelOptions(noHide = F, direction = &#39;auto&#39;)) }) ## [1] &quot;07am - 11am&quot; ## [1] &quot;15pm - 19pm&quot; ## [1] &quot;19pm - 23pm&quot; l %&gt;% addLayersControl( overlayGroups = names(df.df), options = layersControlOptions(collapsed = FALSE) ) map &lt;- leaflet(df) %&gt;% addTiles() %&gt;% addCircleMarkers(~Longitude, ~Latitude, 2, group=~timerange, color=~color, opacity=0.3, label = ~OFNS_DESC, clusterOptions = markerClusterOptions()) %&gt;% addLayersControl( overlayGroups= c(&quot;07am - 11am&quot;, &quot;15pm - 19pm&quot;, &quot;19pm - 23pm&quot;), options = layersControlOptions(collapsed = FALSE), ) map df &lt;- df_select %&gt;% drop_na(Latitude, Longitude) map &lt;- leaflet(df) %&gt;% addTiles() %&gt;% addCircles(~Longitude, ~Latitude, 10, group=~timerange, color=~color, opacity=0.3, label = ~OFNS_DESC) %&gt;% addLayersControl( overlayGroups= c(&quot;07am - 11am&quot;, &quot;15pm - 19pm&quot;, &quot;19pm - 23pm&quot;), options = layersControlOptions(collapsed = FALSE), ) map library(purrr) df &lt;- df_select %&gt;% drop_na(Latitude, Longitude) Y &lt;- split(df, df$timerange) leaf &lt;- leaflet() %&gt;% addTiles() leaf &lt;- leaf %&gt;% addMarkers(data=Y[[1]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, popup=~OFNS_DESC, clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;07am - 11am&quot; ) leaf &lt;- leaf %&gt;%addMarkers(data=Y[[2]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, popup=~OFNS_DESC, clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;15pm - 19pm&quot; ) leaf &lt;- leaf %&gt;% addMarkers(data=Y[[3]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, popup=~OFNS_DESC, clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;19pm - 23pm&quot; ) leaf %&gt;% addLayersControl( overlayGroups = c(&quot;07am - 11am&quot;, &quot;15pm - 19pm&quot;,&quot;19pm - 23pm&quot;), options = layersControlOptions(collapsed = FALSE) ) df &lt;- df_select %&gt;% drop_na(Latitude, Longitude) map &lt;- leaflet(df) %&gt;% addTiles() %&gt;% addCircles(~Longitude, ~Latitude, 10, group=~OFNS_DESC, color=~crime_color, opacity=1, label = ~OFNS_DESC) %&gt;% addLayersControl( overlayGroups= c(&#39;BURGLARY&#39;), options = layersControlOptions(collapsed = FALSE), ) map TYPE &lt;- split(df, df$OFNS_DESC) leaftype &lt;- leaflet() %&gt;% addTiles() #paste (~VIC_AGE_GROUP, sep = &quot; &quot;, collapse = NULL) #TYPE[[1]]$VIC_AGE_GROUP #cat(&#39;a&#39;,&#39;b&#39;,sep = &#39;\\n&#39;) leaftype &lt;- leaftype %&gt;% addMarkers(data=TYPE[[1]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[1]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[1]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;BURGLARY&quot; ) leaftype &lt;- leaftype %&gt;%addMarkers(data=TYPE[[2]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[2]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[2]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;OFFENSE&quot; ) leaftype &lt;- leaftype %&gt;% addMarkers(data=TYPE[[3]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[3]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[3]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;RAPE&quot; ) leaftype &lt;- leaftype %&gt;% addMarkers(data=TYPE[[4]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[4]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[4]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;ROBBERY&quot; ) leaftype &lt;- leaftype %&gt;% addMarkers(data=TYPE[[5]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[5]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[5]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;THIEF&quot; ) leaftype &lt;- leaftype %&gt;% addMarkers(data=TYPE[[6]], lng=~Longitude, lat=~Latitude, label =~OFNS_DESC , popup=paste(paste(&quot;Victim Age: &quot;,TYPE[[6]]$VIC_AGE_GROUP), paste(&quot;, Time: &quot;,TYPE[[6]]$timerange),sep = &#39;\\n&#39;), clusterOptions = markerClusterOptions(removeOutsideVisibleBounds = T), labelOptions = labelOptions(direction = &#39;auto&#39;), group = &quot;WEAPON&quot; ) leaftype %&gt;% addLayersControl( overlayGroups = c(&quot;BURGLARY&quot;,&quot;OFFENSE&quot;,&quot;RAPE&quot;,&quot;ROBBERY&quot;,&quot;THIEF&quot;,&quot;WEAPON&quot;), options = layersControlOptions(collapsed = FALSE) ) df &lt;- df_select %&gt;% drop_na(Latitude, Longitude) TYPE &lt;- split(df, df$OFNS_DESC) TYPE[[1]] ## BORO_NM CMPLNT_FR_DT CMPLNT_FR_TM OFNS_DESC SUSP_AGE_GROUP ## 722 BROOKLYN 2019-01-02 18:10:00 BURGLARY &lt;NA&gt; ## 724 MANHATTAN 2018-12-31 18:00:00 BURGLARY UNKNOWN ## 138440 QUEENS 2019-01-22 07:30:00 BURGLARY UNKNOWN ## 138473 BRONX 2019-01-21 19:45:00 BURGLARY UNKNOWN ## 139034 BROOKLYN 2019-01-20 07:00:00 BURGLARY UNKNOWN ## 139298 QUEENS 2019-01-21 21:00:00 BURGLARY 18-24 ## 139537 BROOKLYN 2019-01-15 10:00:00 BURGLARY &lt;NA&gt; ## 139635 BROOKLYN 2019-01-21 18:30:00 BURGLARY &lt;NA&gt; ## 139779 MANHATTAN 2019-01-18 18:00:00 BURGLARY &lt;NA&gt; ## 140211 BRONX 2019-01-20 21:27:00 BURGLARY UNKNOWN ## 140260 BROOKLYN 2019-01-18 15:00:00 BURGLARY UNKNOWN ## 140467 BROOKLYN 2019-01-21 16:00:00 BURGLARY &lt;NA&gt; ## 141127 BRONX 2019-01-17 20:00:00 BURGLARY &lt;NA&gt; ## 141334 STATEN ISLAND 2019-01-08 17:00:00 BURGLARY &lt;NA&gt; ## 141404 MANHATTAN 2019-01-17 10:30:00 BURGLARY UNKNOWN ## 142212 QUEENS 2019-01-18 15:30:00 BURGLARY &lt;NA&gt; ## 142221 BROOKLYN 2019-01-21 20:35:00 BURGLARY UNKNOWN ## 142371 STATEN ISLAND 2019-01-18 16:00:00 BURGLARY UNKNOWN ## 142904 MANHATTAN 2019-01-21 10:30:00 BURGLARY &lt;NA&gt; ## 144158 BROOKLYN 2019-01-13 20:30:00 BURGLARY &lt;NA&gt; ## 144163 QUEENS 2019-01-16 16:00:00 BURGLARY UNKNOWN ## 144188 BROOKLYN 2019-01-07 09:00:00 BURGLARY &lt;NA&gt; ## 144195 QUEENS 2019-01-08 11:00:00 BURGLARY &lt;NA&gt; ## 144216 BROOKLYN 2019-01-20 22:00:00 BURGLARY &lt;NA&gt; ## 144300 BRONX 2019-01-20 07:30:00 BURGLARY &lt;NA&gt; ## 144308 QUEENS 2019-01-11 07:50:00 BURGLARY UNKNOWN ## 144324 BRONX 2019-01-11 19:00:00 BURGLARY 25-44 ## 144337 BROOKLYN 2019-01-14 18:23:00 BURGLARY &lt;NA&gt; ## 144373 BROOKLYN 2019-01-17 08:35:00 BURGLARY UNKNOWN ## 144404 BRONX 2019-01-18 18:24:00 BURGLARY 25-44 ## 144416 BRONX 2018-12-31 17:30:00 BURGLARY 18-24 ## 144424 QUEENS 2019-01-14 19:00:00 BURGLARY &lt;NA&gt; ## 144425 QUEENS 2019-01-20 10:40:00 BURGLARY 18-24 ## 144486 QUEENS 2019-01-14 09:15:00 BURGLARY &lt;NA&gt; ## 144545 QUEENS 2019-01-14 22:25:00 BURGLARY 25-44 ## 144609 BROOKLYN 2019-01-20 15:59:00 BURGLARY 45-64 ## 144661 STATEN ISLAND 2019-01-18 10:00:00 BURGLARY &lt;NA&gt; ## 144723 MANHATTAN 2019-01-11 10:45:00 BURGLARY UNKNOWN ## 144793 BRONX 2019-01-12 20:20:00 BURGLARY 45-64 ## 144815 QUEENS 2019-01-18 17:00:00 BURGLARY &lt;NA&gt; ## 144858 MANHATTAN 2019-01-14 22:30:00 BURGLARY 25-44 ## 144903 QUEENS 2019-01-15 19:05:00 BURGLARY &lt;NA&gt; ## 144908 QUEENS 2019-01-18 07:45:00 BURGLARY &lt;NA&gt; ## 144916 QUEENS 2019-01-09 19:00:00 BURGLARY &lt;NA&gt; ## 145032 BROOKLYN 2019-01-16 21:00:00 BURGLARY UNKNOWN ## 145035 MANHATTAN 2019-01-12 18:00:00 BURGLARY UNKNOWN ## 145070 QUEENS 2019-01-12 18:00:00 BURGLARY &lt;NA&gt; ## 145114 BRONX 2019-01-16 20:30:00 BURGLARY 25-44 ## 145177 QUEENS 2019-01-17 10:30:00 BURGLARY &lt;NA&gt; ## 145190 BRONX 2019-01-13 15:18:00 BURGLARY &lt;NA&gt; ## 145213 QUEENS 2019-01-11 08:00:00 BURGLARY UNKNOWN ## 145304 QUEENS 2019-01-16 17:25:00 BURGLARY &lt;NA&gt; ## 145322 BRONX 2018-12-23 22:00:00 BURGLARY UNKNOWN ## 145337 MANHATTAN 2019-01-14 08:00:00 BURGLARY UNKNOWN ## 145371 BROOKLYN 2019-01-11 15:30:00 BURGLARY &lt;NA&gt; ## 145394 QUEENS 2019-01-12 15:55:00 BURGLARY UNKNOWN ## 145421 BROOKLYN 2019-01-16 08:45:00 BURGLARY UNKNOWN ## 145427 MANHATTAN 2019-01-15 17:00:00 BURGLARY &lt;NA&gt; ## 145456 BROOKLYN 2019-01-18 09:00:00 BURGLARY &lt;NA&gt; ## 145469 QUEENS 2019-01-12 22:30:00 BURGLARY 25-44 ## 145503 BRONX 2019-01-12 16:00:00 BURGLARY &lt;NA&gt; ## 145556 MANHATTAN 2019-01-11 16:30:00 BURGLARY UNKNOWN ## PREM_TYP_DESC SUSP_SEX SUSP_RACE VIC_AGE_GROUP ## 722 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 724 COMMERCIAL BUILDING M BLACK UNKNOWN ## 138440 RESIDENCE-HOUSE U UNKNOWN 25-44 ## 138473 CHURCH U UNKNOWN UNKNOWN ## 139034 RESIDENCE - APT. HOUSE U UNKNOWN 25-44 ## 139298 RESIDENCE - PUBLIC HOUSING M WHITE 18-24 ## 139537 CONSTRUCTION SITE &lt;NA&gt; &lt;NA&gt; 25-44 ## 139635 COMMERCIAL BUILDING &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 139779 STREET &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 140211 &lt;NA&gt; M BLACK UNKNOWN ## 140260 RESIDENCE-HOUSE U UNKNOWN 45-64 ## 140467 STREET &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 141127 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 141334 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 141404 RESIDENCE - APT. HOUSE M BLACK 25-44 ## 142212 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 45-64 ## 142221 FAST FOOD M UNKNOWN UNKNOWN ## 142371 CONSTRUCTION SITE U UNKNOWN UNKNOWN ## 142904 STREET &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 144158 STREET &lt;NA&gt; &lt;NA&gt; 25-44 ## 144163 RESIDENCE-HOUSE U UNKNOWN 45-64 ## 144188 RESIDENCE - PUBLIC HOUSING &lt;NA&gt; &lt;NA&gt; 18-24 ## 144195 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 144216 RESIDENCE - APT. HOUSE &lt;NA&gt; &lt;NA&gt; 25-44 ## 144300 CHAIN STORE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 144308 RESIDENCE - APT. HOUSE U UNKNOWN 25-44 ## 144324 RESIDENCE - APT. HOUSE M BLACK 45-64 ## 144337 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 144373 RESIDENCE - APT. HOUSE U UNKNOWN 45-64 ## 144404 RESIDENCE - APT. HOUSE M BLACK 25-44 ## 144416 RESIDENCE - APT. HOUSE M BLACK HISPANIC 25-44 ## 144424 RESIDENCE - APT. HOUSE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 144425 RESIDENCE-HOUSE M BLACK 45-64 ## 144486 RESIDENCE - APT. HOUSE &lt;NA&gt; &lt;NA&gt; 25-44 ## 144545 RESIDENCE-HOUSE M BLACK 45-64 ## 144609 RESIDENCE-HOUSE M BLACK UNKNOWN ## 144661 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 45-64 ## 144723 RESIDENCE-HOUSE M WHITE HISPANIC 65+ ## 144793 RESIDENCE - PUBLIC HOUSING M BLACK HISPANIC 45-64 ## 144815 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 45-64 ## 144858 DRUG STORE M BLACK UNKNOWN ## 144903 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 144908 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 25-44 ## 144916 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 145032 RESIDENCE - APT. HOUSE U UNKNOWN 18-24 ## 145035 RESIDENCE - APT. HOUSE U UNKNOWN 45-64 ## 145070 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 145114 RESIDENCE - APT. HOUSE M WHITE HISPANIC UNKNOWN ## 145177 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 65+ ## 145190 CONSTRUCTION SITE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 145213 RESIDENCE - APT. HOUSE U UNKNOWN 65+ ## 145304 RESIDENCE-HOUSE &lt;NA&gt; &lt;NA&gt; 45-64 ## 145322 RESIDENCE - APT. HOUSE U UNKNOWN UNKNOWN ## 145337 RESIDENCE-HOUSE U UNKNOWN 45-64 ## 145371 CONSTRUCTION SITE &lt;NA&gt; &lt;NA&gt; UNKNOWN ## 145394 OTHER M WHITE HISPANIC 45-64 ## 145421 RESIDENCE - APT. HOUSE U UNKNOWN 25-44 ## 145427 RESIDENCE - APT. HOUSE &lt;NA&gt; &lt;NA&gt; 45-64 ## 145456 RESIDENCE - APT. HOUSE &lt;NA&gt; &lt;NA&gt; 25-44 ## 145469 SYNAGOGUE M WHITE HISPANIC UNKNOWN ## 145503 RESIDENCE - PUBLIC HOUSING &lt;NA&gt; &lt;NA&gt; 25-44 ## 145556 RESIDENCE - APT. HOUSE U UNKNOWN 25-44 ## VIC_RACE VIC_SEX Latitude Longitude ## 722 UNKNOWN D 40.69163 -73.98630 ## 724 UNKNOWN D 40.74603 -73.99239 ## 138440 ASIAN / PACIFIC ISLANDER F 40.72377 -73.75442 ## 138473 UNKNOWN D 40.81615 -73.90516 ## 139034 WHITE M 40.70354 -73.98956 ## 139298 WHITE F 40.76078 -73.93415 ## 139537 UNKNOWN M 40.70115 -73.94013 ## 139635 UNKNOWN D 40.66973 -73.86147 ## 139779 UNKNOWN D 40.73638 -73.97461 ## 140211 UNKNOWN D 40.85802 -73.83486 ## 140260 ASIAN / PACIFIC ISLANDER M 40.68212 -73.96460 ## 140467 UNKNOWN D 40.68620 -73.87622 ## 141127 UNKNOWN D 40.88905 -73.85133 ## 141334 WHITE F 40.62398 -74.15997 ## 141404 WHITE HISPANIC M 40.74290 -73.98019 ## 142212 WHITE M 40.75006 -73.76366 ## 142221 UNKNOWN D 40.64028 -74.00458 ## 142371 UNKNOWN D 40.62912 -74.11478 ## 142904 UNKNOWN D 40.75680 -73.99753 ## 144158 WHITE HISPANIC M 40.66296 -73.93224 ## 144163 ASIAN / PACIFIC ISLANDER M 40.70811 -73.76733 ## 144188 BLACK F 40.66452 -73.90659 ## 144195 WHITE M 40.72101 -73.77855 ## 144216 WHITE HISPANIC M 40.66181 -73.99116 ## 144300 UNKNOWN D 40.87863 -73.90501 ## 144308 WHITE M 40.76171 -73.91124 ## 144324 BLACK F 40.87945 -73.86591 ## 144337 ASIAN / PACIFIC ISLANDER M 40.60351 -73.98726 ## 144373 WHITE F 40.68186 -73.99239 ## 144404 BLACK F 40.84298 -73.91458 ## 144416 BLACK F 40.84305 -73.92048 ## 144424 UNKNOWN D 40.59913 -73.75654 ## 144425 BLACK M 40.69204 -73.77420 ## 144486 WHITE M 40.76293 -73.91468 ## 144545 BLACK M 40.66871 -73.77621 ## 144609 UNKNOWN E 40.68273 -73.94837 ## 144661 BLACK HISPANIC M 40.63413 -74.11614 ## 144723 BLACK F 40.80803 -73.94109 ## 144793 WHITE HISPANIC M 40.87007 -73.90611 ## 144815 ASIAN / PACIFIC ISLANDER M 40.74745 -73.77978 ## 144858 UNKNOWN D 40.78995 -73.97535 ## 144903 ASIAN / PACIFIC ISLANDER M 40.76129 -73.73248 ## 144908 ASIAN / PACIFIC ISLANDER M 40.75225 -73.74016 ## 144916 BLACK F 40.72676 -73.80193 ## 145032 BLACK F 40.68866 -73.93917 ## 145035 WHITE M 40.78183 -73.94732 ## 145070 WHITE HISPANIC F 40.72449 -73.88211 ## 145114 UNKNOWN D 40.83026 -73.90621 ## 145177 ASIAN / PACIFIC ISLANDER M 40.74958 -73.78829 ## 145190 UNKNOWN D 40.81325 -73.92869 ## 145213 WHITE M 40.76171 -73.91124 ## 145304 ASIAN / PACIFIC ISLANDER M 40.73741 -73.79107 ## 145322 UNKNOWN D 40.84776 -73.91346 ## 145337 BLACK M 40.80611 -73.94557 ## 145371 UNKNOWN D 40.67707 -73.98319 ## 145394 ASIAN / PACIFIC ISLANDER M 40.69864 -73.90653 ## 145421 BLACK HISPANIC F 40.65273 -73.94832 ## 145427 BLACK HISPANIC M 40.84987 -73.93978 ## 145456 WHITE F 40.64541 -73.96979 ## 145469 UNKNOWN D 40.72636 -73.82298 ## 145503 AMERICAN INDIAN/ALASKAN NATIVE M 40.85037 -73.91726 ## 145556 WHITE HISPANIC M 40.79625 -73.97346 ## timerange color crimecolor ## 722 15pm - 19pm green #7851a9 ## 724 15pm - 19pm green #7851a9 ## 138440 07am - 11am red #7851a9 ## 138473 19pm - 23pm blue #7851a9 ## 139034 07am - 11am red #7851a9 ## 139298 19pm - 23pm blue #7851a9 ## 139537 07am - 11am red #7851a9 ## 139635 15pm - 19pm green #7851a9 ## 139779 15pm - 19pm green #7851a9 ## 140211 19pm - 23pm blue #7851a9 ## 140260 15pm - 19pm green #7851a9 ## 140467 15pm - 19pm green #7851a9 ## 141127 19pm - 23pm blue #7851a9 ## 141334 15pm - 19pm green #7851a9 ## 141404 07am - 11am red #7851a9 ## 142212 15pm - 19pm green #7851a9 ## 142221 19pm - 23pm blue #7851a9 ## 142371 15pm - 19pm green #7851a9 ## 142904 07am - 11am red #7851a9 ## 144158 19pm - 23pm blue #7851a9 ## 144163 15pm - 19pm green #7851a9 ## 144188 07am - 11am red #7851a9 ## 144195 07am - 11am red #7851a9 ## 144216 19pm - 23pm blue #7851a9 ## 144300 07am - 11am red #7851a9 ## 144308 07am - 11am red #7851a9 ## 144324 19pm - 23pm blue #7851a9 ## 144337 15pm - 19pm green #7851a9 ## 144373 07am - 11am red #7851a9 ## 144404 15pm - 19pm green #7851a9 ## 144416 15pm - 19pm green #7851a9 ## 144424 19pm - 23pm blue #7851a9 ## 144425 07am - 11am red #7851a9 ## 144486 07am - 11am red #7851a9 ## 144545 19pm - 23pm blue #7851a9 ## 144609 15pm - 19pm green #7851a9 ## 144661 07am - 11am red #7851a9 ## 144723 07am - 11am red #7851a9 ## 144793 19pm - 23pm blue #7851a9 ## 144815 15pm - 19pm green #7851a9 ## 144858 19pm - 23pm blue #7851a9 ## 144903 19pm - 23pm blue #7851a9 ## 144908 07am - 11am red #7851a9 ## 144916 19pm - 23pm blue #7851a9 ## 145032 19pm - 23pm blue #7851a9 ## 145035 15pm - 19pm green #7851a9 ## 145070 15pm - 19pm green #7851a9 ## 145114 19pm - 23pm blue #7851a9 ## 145177 07am - 11am red #7851a9 ## 145190 15pm - 19pm green #7851a9 ## 145213 07am - 11am red #7851a9 ## 145304 15pm - 19pm green #7851a9 ## 145322 19pm - 23pm blue #7851a9 ## 145337 07am - 11am red #7851a9 ## 145371 15pm - 19pm green #7851a9 ## 145394 15pm - 19pm green #7851a9 ## 145421 07am - 11am red #7851a9 ## 145427 15pm - 19pm green #7851a9 ## 145456 07am - 11am red #7851a9 ## 145469 19pm - 23pm blue #7851a9 ## 145503 15pm - 19pm green #7851a9 ## 145556 15pm - 19pm green #7851a9 ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 343 rows ] leaftype &lt;- leaflet() %&gt;% addTiles() #addCircles(~Longitude, ~Latitude, 10, group=~OFNS_DESC, color=~crime_color, opacity=1, label = ~OFNS_DESC) leaftype &lt;- leaftype %&gt;% addCircles(data=TYPE[[1]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;red&quot;, group = &quot;BURGLARY&quot; ) leaftype &lt;- leaftype %&gt;%addCircles(data=TYPE[[2]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;orange&quot;, group = &quot;OFFENSE&quot; ) leaftype &lt;- leaftype %&gt;% addCircles(data=TYPE[[3]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;pink&quot;, group = &quot;RAPE&quot; ) leaftype &lt;- leaftype %&gt;% addCircles(data=TYPE[[4]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;blue&quot;, group = &quot;ROBBERY&quot; ) leaftype &lt;- leaftype %&gt;% addCircles(data=TYPE[[5]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;green&quot;, group = &quot;THIEF&quot; ) leaftype &lt;- leaftype %&gt;% addCircles(data=TYPE[[6]], lng=~Longitude, lat=~Latitude, label=~OFNS_DESC, weight = 10, opacity=1, color=&quot;white&quot;, group = &quot;WEAPON&quot; ) leaftype %&gt;% addLayersControl( overlayGroups = c(&quot;BURGLARY&quot;,&quot;OFFENSE&quot;,&quot;RAPE&quot;,&quot;ROBBERY&quot;,&quot;THIEF&quot;,&quot;WEAPON&quot;), options = layersControlOptions(collapsed = FALSE) ) "]
]
